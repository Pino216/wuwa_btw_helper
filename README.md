# 鸣潮·踏潮探历算法助手 🤖

一个专为《鸣潮》游戏内"踏潮探历"活动设计的智能决策工具，通过多种算法策略帮助玩家以最优方式完成7×7坐标网格探索。

## ✨ 核心特性

### 🎯 智能算法引擎
- **贪心算法（利益至上）**：直接最大化当前点击的期望收益，根据用户概率动态调整权重
- **带权启发（战略布局）**：采用α·g(n) + β·w·h(n)的平衡设计，可动态调整探索权重
- **熵减算法（风险对冲）**：优先清理孤立格子，减少分散风险，在游戏后期表现更佳
- **综合推荐（算法融合）**：结合多种算法结果进行综合评分，可自定义参与计算的算法组合
- **蒙特卡洛搜索（深度前瞻）**：多步深度前瞻算法，支持稳定性模式减少随机波动
- **快速蒙特卡洛（平衡型）**：性能与效果平衡的蒙特卡洛变体
- **权重自动调整**：带权启发算法的权重可根据游戏阶段自动动态变化

### 🔧 高级功能
- **软保底系统**：模拟游戏保底机制，当连续X次未触发事件时概率逐步提升，Y次后必触发非类型1事件
- **批量模拟分析**：运行数千次模拟，对比不同算法的平均点击次数和方差
- **实时概率调整**：根据保底计数动态调整7种事件类型的触发概率
- **算法综合配置**：可自定义参与综合推荐的算法组合

### 📱 用户体验
- **响应式设计**：完美适配桌面端和移动端，针对不同屏幕尺寸优化布局
- **智能折叠面板**：移动端自动折叠配置面板，为网格提供更多显示空间
- **直观可视化**：红/橙颜色标记最优和次优选择，绿色边框标记多算法推荐
- **本地存储**：自动保存游戏进度和所有设置
- **音效反馈**：Web Audio API提供操作音效增强沉浸感
- **移动端优化**：全宽长方形按钮、触摸友好的交互设计

## 🚀 快速开始

### 基本使用
1. **打开工具**：在浏览器中打开 `index.html` 文件
2. **开始探索**：点击7×7网格中的任意未开启格子
3. **选择事件**：从弹出菜单中选择要触发的事件类型（1-7）
4. **跟随推荐**：
   - 🔴 **红色格子**：算法推荐的最优选择
   - 🟠 **橙色格子**：次优选择（分数 > 最优分数的80%）
   - 🟢 **绿色边框**：被多个算法推荐的格子（仅在综合推荐模式下显示）

### 配置说明
- **概率权重**：调整7种事件类型的触发概率（总和建议100%）
- **保底设置**：
  - 启用/禁用保底系统
  - 设置保底起始值（X）和上限值（Y）
  - 默认：起始3次，上限5次必触发非类型1事件
- **算法选择**：
  - 手动选择固定算法（贪心、带权启发、熵减、综合推荐、蒙特卡洛搜索、快速蒙特卡洛）
  - 带权启发算法支持权重自动调整开关
  - 综合推荐算法可自定义参与计算的算法组合
- **布局控制**：
  - 桌面端：侧边栏可折叠，节省屏幕空间
  - 移动端：配置面板默认折叠，点击"显示设置"展开

### 批量模拟
1. 在侧边栏设置模拟次数（10-10000次）
2. 勾选要包含的算法（注意：蒙特卡洛算法消耗大量性能）
3. 点击"开始批量模拟"
4. 查看对比结果：
   - 平均点击次数、方差、标准差
   - 算法性能对比表格

## 🧠 算法深度解析

#### 算法表现分析
经过大量模拟测试发现，在当前游戏机制下，**智能算法与纯随机选择的平均点击次数差距有限**（通常为0.1-0.4次）。这主要源于游戏设计本身的特点：

1. **事件触发与位置解耦**：事件类型的触发概率与选择的格子位置无关，算法只能优化"如果触发高效事件能开多少格子"，而不能影响"触发高效事件的概率"
2. **高效事件普惠性**：即使随机选择，也有较高概率触发能开启多个格子的事件（类型2-7合计概率通常>50%）
3. **保底机制平衡**：软保底系统确保连续"失败"后高效事件概率提升，进一步缩小策略差异

#### 蒙特卡洛算法实际表现
在最新版本中，我们引入了**蒙特卡洛树搜索（MCTS）** 和**快速蒙特卡洛**算法，并针对性能进行了专门优化。然而，根据大量实际测试发现：

**蒙特卡洛算法在当前游戏机制下并没有明显优势**，主要原因包括：

1. **游戏机制限制**：事件触发与格子位置完全解耦，蒙特卡洛的多步前瞻优势无法充分发挥
2. **计算成本高**：相比其他算法，蒙特卡洛需要更多计算资源，但收益有限
3. **随机性主导**：游戏本身的高效事件概率较高，随机选择已有不错表现

**优化措施**：
- **异步分片执行**：批量模拟时采用异步分片技术，避免阻塞用户界面
- **智能次数控制**：根据算法复杂度动态调整模拟次数（蒙特卡洛50-100次，其他算法1000次）
- **稳定性模式**：蒙特卡洛算法支持稳定性模式，通过多次运行取平均值减少随机波动
- **进度实时反馈**：在批量测试过程中实时显示每个算法的测试进度

**重要更新**：在最新版本中，**移除了动态算法切换功能**，用户需要手动选择算法。这是因为自动切换在实际使用中可能导致困惑，且各算法在不同阶段的优势差异有限。

**实际建议**：由于计算成本高且优势有限，**不建议在日常使用中优先选择蒙特卡洛算法**。它更适合作为算法学习案例，展示高级搜索算法的实现思路。对于日常使用，推荐使用**贪心算法**或**综合推荐算法**。

#### 算法价值定位
虽然算法在点击次数上的优势有限，但其核心价值在于：
- **策略性体验**：提供可解释的选择理由，增加游戏策略深度
- **稳定性提升**：减少极端情况，提供更一致的体验
- **教育意义**：展示贪心、启发式、熵减、蒙特卡洛等算法的实际应用和思考过程
- **算法对比**：通过批量模拟直观展示不同算法在相同条件下的表现差异

#### 事件类型与收益计算
工具计算7种事件类型的期望收益：
1. **仅当前格子** 📍 - 基础收益
2. **同列所有格子** ↕️ - 列收益
3. **同行所有格子** ↔️ - 行收益
4. **同行同列** ➕ - 行列组合收益
5. **十字区域** 💠 - 四连通收益
6. **九宫格区域** 🍷 - 八连通收益
7. **全图开启** 🌟 - 全局收益

#### 算法实现特点
- **贪心算法**：根据用户概率动态调整权重，当某种类型事件概率高时增强对应指标的重要性
- **带权启发算法**：采用α·g(n) + β·w·h(n)的平衡设计，根据游戏阶段动态调整潜力评估权重
- **熵减算法**：优先清理孤立格子，在游戏后期表现更佳
- **综合推荐**：融合多种算法结果，提供更稳健的推荐

#### 软保底机制实现
- **计数规则**：仅当触发类型1事件时，未触发计数增加
- **概率调整**：当计数≥X时，类型1概率逐步减少，其他类型概率按比例增加
- **必触发保证**：当计数达到Y时，必触发类型2-7中的一种事件

#### 权重自动调整策略
带权启发算法支持权重自动调整功能，根据游戏阶段智能调整探索权重：
- **前期**（>30格）：权重较高（1.5-2.0），注重探索未开启区域
- **中期**（10-30格）：权重适中（1.0-1.5），平衡探索与利用
- **后期**（<10格）：权重较低（0.5-1.0），更注重直接收益

### 响应式布局设计
- **桌面端**：
  - 侧边配置面板固定定位，网格区域自适应
  - 圆形折叠按钮位于面板右侧，节省空间
  - 最大高度限制，支持滚动查看所有配置项
  
- **移动端**：
  - 垂直布局：网格在上，配置面板在下
  - 配置面板默认折叠，点击全宽长方形按钮展开
  - 网格使用`aspect-ratio`保持正方形，自适应屏幕宽度
  - 超小屏幕（<360px）进一步优化字体和间距

## 🛠️ 技术架构

### 核心技术栈
- **前端框架**：纯原生HTML5/CSS3/JavaScript（单文件应用）
- **状态管理**：localStorage持久化存储
- **音频系统**：Web Audio API动态生成音效
- **响应式布局**：CSS媒体查询+Flexbox/Grid布局

### 核心数据结构
```javascript
const state = {
    grid: Array(49).fill(false),      // 7×7网格状态（true=已开启）
    probs: [50, 11, 11, 5, 13, 9, 1], // 7种事件概率权重（默认值）
    clicks: 0,                         // 当前点击次数
    enablePity: true,                  // 保底系统开关
    pityStart: 3,                      // 保底起始计数X
    pityMax: 5,                        // 保底上限计数Y
    currentMisses: 0,                  // 当前未触发计数
    currentAlgorithm: 'greedy',        // 当前使用算法
    heuristicWeight: 1.0,              // 启发式算法权重
    autoWeight: true,                  // 权重自动调整开关
    mctsIterations: 300,               // 蒙特卡洛迭代次数
    mctsStable: true,                  // 蒙特卡洛稳定性模式
    comprehensiveAlgorithms: {         // 综合推荐算法选择
        greedy: true,
        heuristic: true,
        entropy: true,
        mcts: false
    }
};
```

### 文件结构
```
项目根目录/
├── index.html                 # 主程序文件
├── README.md                  # 项目说明文档
├── .gitignore                 # Git忽略配置
├── script.js                  # 核心算法
└──style.css                   # 样式文件
```

## 📈 使用策略建议

### 不同阶段的最佳实践
- **开局阶段**（剩余40+格）：
  - 使用带权启发算法，开启权重自动调整
  - 注意：此阶段算法优势有限，随机选择也有不错表现
  
- **中期阶段**（剩余15-40格）：
  - 根据格子分布选择算法：
    - 孤立格子多（>30%）→ 熵减算法
    - 格子分布均匀 → 贪心算法
    - 复杂局面 → 快速蒙特卡洛算法
  - 关注保底计数，合理利用概率提升期
  
- **收尾阶段**（剩余<15格）：
  - 推荐使用熵减算法
  - 蒙特卡洛算法计算成本高且优势有限，不建议使用
  - 优先清理邻居少的孤立格子
  - 注意：此阶段算法选择对最终点击次数影响较小

#### 重要提醒
由于游戏机制设计，**算法与纯随机选择的差距通常不大**。建议将本工具视为：
1. **算法学习工具**：理解不同算法的决策逻辑
2. **策略思考助手**：提供有依据的选择建议
3. **概率教学演示**：展示期望值计算和概率调整

### 保底系统优化
- 根据游戏实际设置合适的X/Y值
- 默认X=3,Y=5已针对活动优化
- 可通过批量模拟测试不同保底参数的效果

## ❓ 常见问题

### 概率权重相关问题
**Q: 概率权重总和不是100%可以吗？**  
A: 可以，程序会自动归一化处理，但建议设为100%以获得直观效果。

**Q: 如何重置概率权重？**  
A: 点击"重置进度"按钮，或手动修改输入框数值。

### 算法相关问题
**Q: 为什么算法与随机选择的差距不大？**  
A: 这是由游戏机制决定的：1) 事件触发与格子位置无关；2) 高效事件概率较高；3) 保底机制进一步平衡表现。算法的主要价值在于提供策略性思考而非大幅优化结果。

**Q: 贪心算法为什么通常表现较好？**  
A: 贪心算法直接最大化当前点击的期望收益，在当前游戏机制下这是有效的策略。其他算法（启发式、熵减）在特定场景下可能有优势，但整体差异有限。

**Q: 蒙特卡洛算法会导致网页卡死吗？**  
A: 在最新版本中，我们已经对蒙特卡洛算法进行了性能优化：1) 采用异步分片执行技术；2) 动态减少模拟次数；3) 添加进度反馈。现在批量测试蒙特卡洛算法不会卡死界面，但计算时间仍比其他算法长。

**Q: 蒙特卡洛算法在实际测试中表现如何？**  
A: 根据大量实际测试，蒙特卡洛算法在当前游戏机制下**并未表现出明显优势**。虽然理论上具有多步前瞻能力，但由于事件触发与格子位置解耦，其优势无法充分发挥。计算成本远高于收益，**不建议在日常使用中优先选择**。

**Q: 为什么移除了动态算法切换功能？**  
A: 动态算法切换在实际使用中发现可能导致困惑，且各算法在不同阶段的优势差异有限。手动选择算法能让用户更清楚地了解当前使用的策略，并提供更可控的体验。

**Q: 权重自动调整如何工作？**  
A: 当开启权重自动调整时，系统会根据当前游戏阶段（前期、中期、后期）自动调整带权启发算法的探索权重值，前期更注重探索，后期更注重直接收益。

**Q: 综合推荐算法如何选择参与算法？**  
A: 在综合推荐模式下，可以勾选参与计算的算法（贪心、带权启发、熵减、蒙特卡洛），系统会计算这些算法的平均分数作为最终推荐。

**Q: 算法的实际优势在哪里？**  
A: 虽然点击次数优化有限，但算法提供了：1) 可解释的决策理由；2) 更稳定的表现（减少方差）；3) 策略思考的乐趣；4) 算法学习的实践案例；5) 蒙特卡洛等高级算法的实际应用展示。

**Q: 蒙特卡洛算法适合什么阶段使用？**  
A: 蒙特卡洛算法计算成本较高，但在复杂局面下表现优异：1) **前期**：计算开销大，优势不明显；2) **中期**：开始展现多步前瞻的优势；3) **后期**（剩余<15格）：通常表现最佳，能处理复杂局面。但由于其计算成本高且优势有限，**建议仅在需要学习算法原理时使用**。

### 布局与界面问题
**Q: 在手机上配置面板为什么默认折叠？**  
A: 为了在移动端提供更大的网格显示空间，配置面板默认折叠。点击"显示设置"按钮即可展开。

**Q: 如何切换桌面端和移动端布局？**  
A: 布局会根据屏幕宽度自动切换。桌面端（宽度>768px）使用左右布局，移动端使用上下布局。

**Q: 移动端的切换按钮为什么是长方形？**  
A: 长方形按钮提供更大的触摸区域，并可以显示完整文字（"显示设置"/"隐藏设置"），提高移动端操作便利性。

### 技术问题
**Q: 数据存储在哪里？**  
A: 所有数据存储在浏览器的localStorage中，清除浏览器数据会丢失进度。

**Q: 支持移动设备吗？**  
A: 完全支持！工具采用响应式设计，在手机和平板上均可正常使用，并针对移动端进行了专门优化。

**Q: 需要网络连接吗？**  
A: 不需要，所有功能均在本地运行，打开HTML文件即可使用。

## 🔄 更新日志

### v1.2 (当前版本)
- **算法评分归一化**：改进所有算法的评分系统，确保不同算法的分数在同一尺度上可比
- **移除动态切换**：移除了自动切换算法功能，用户需要手动选择最适合当前阶段的算法
- **综合推荐增强**：改进综合推荐算法，允许用户自定义参与计算的算法组合
- **蒙特卡洛优化**：进一步优化蒙特卡洛算法的性能，减少内存使用
- **批量模拟改进**：更新批量模拟界面，提供更清晰的算法性能对比
- **移动端体验优化**：改进移动端折叠面板的交互逻辑，提供更流畅的用户体验
- **代码重构**：清理和优化JavaScript代码结构，提高可维护性

### v1.1
- **多算法支持**：添加三种核心算法
- **批量模拟**：引入统计分析和热力图
- **保底系统**：实现软保底概率调整机制

### v1.0
- **基础版本**：7×7网格交互
- **贪心算法**：基础期望收益计算
- **本地存储**：进度自动保存

## 🤝 贡献与支持

### 开发团队
本项目由 **B站@Dark噫术家** 独立开发维护。

### 重要说明
本项目最初旨在探索算法在游戏中的优化潜力，但测试发现：
- **游戏机制本身限制了算法的优势空间**：事件触发与位置选择解耦，高效事件普惠
- **算法的价值更多体现在教育性和策略性**：提供算法实践案例和策略思考
- **符合游戏设计初衷**：让所有玩家（包括随机选择）都有良好体验

### 问题反馈
如遇到问题或有改进建议：
1. 检查[常见问题](#-常见问题)部分
2. 通过GitHub Issues提交问题报告
3. 在B站联系作者获取支持

### 贡献指南
欢迎提交Pull Request改进：
- **算法教育内容**：增加算法原理和策略分析
- **界面改进方案**：优化用户体验和可视化
- **文档完善**：补充测试结果和分析
- **Bug修复**：修复程序错误

## 📄 许可证

本项目采用 **学习交流许可证**：
- 可自由使用、修改、分发
- 禁止用于商业用途
- 保留原作者署名
- 不提供任何担保

---

**🎮 探索算法之美，理解策略之妙！**  
*虽然算法在点击次数上的优化有限，但本项目展示了：*
- *多种算法的实现与对比*
- *概率与期望值的实际应用*
- *策略思考的价值与乐趣*

> 提示：本项目更多是算法学习工具而非游戏优化工具。游戏活动规则可能调整，算法表现也会相应变化。
